# M2D Tagging Model Configuration
# This config trains the M2D sound event detection model

task_name: m2d_tagging
description: Train M2D sound event detection model

# Wandb configuration
wandb_entity: cp_tobi

# Data copying configuration
# Set to false to disable copying data to local storage (slower but uses less disk space)
enable_data_copy: true

deterministic: true
manual_seed: 0

datamodule:
    module: src.datamodules.datamodule
    main: DataModule
    args:
        train_dataloader:
            batch_size: 32
            num_workers: 16
            persistent_workers: false
            dataset:
                module: src.datamodules.dataset.s5.dataset_s5
                main: DatasetS5
                args:
                    config:
                        spatialscaper:
                            foreground_dir: "data/dev_set/sound_event/train"
                            background_dir: "data/dev_set/noise/train"
                            rir_dir: "data/dev_set/room_ir/train"
                            interference_dir: "data/dev_set/interference/train"
                            duration: 10.0
                            sr: 32000
                            max_event_overlap: 3
                            ref_db: -50
                            return_dry: false
                            return_wet: false
                            return_ir: false
                            return_background: false
                            ref_channel: -1
                            spatialize_direct_path_time_ms: null
                        snr_range: [5, 20]
                        nevent_range: [1, 3]
                        inteference_snr_range: [0, 15]
                        ninterference_range: [1, 2]
                        dataset_length: 10000
                        shuffle_label: false
                    use_full: false
                    n_sources: 3
                    label_set: dcase2025t4
                    return_dry: false
                    label_vector_mode: multihot
                    checking: false
                    use_additional_irs: false
        val_dataloader:
            batch_size: 32
            num_workers: 5
            persistent_workers: false
            dataset:
                module: src.datamodules.dataset.s5.dataset_s5
                main: DatasetS5
                args:
                    config: 'data/dev_set/metadata/valid.json'
                    n_sources: 3
                    label_set: dcase2025t4
                    return_dry: false
                    label_vector_mode: multihot
                    checking: false

lightning_module:
    module: src.training.lightningmodule.sound_event_detection
    main: SoundEventDetection
    args:
        model:
            module: src.models.wrapper
            main: Wrapper
            args:
                model_name: m2d
                checkpoint: strong
                num_classes: 18
                ref_channel: 0
                data_sr: 32000
                target_sr: 16000
                down_up_sample: True
                head_type: attention
                freq_warp_p: 0.0
                use_head_norm: true
                seq_model_type: null
        mixup_p: 0.0
        weak_loss_weight: 0.5
        loss:
            module: src.training.loss.bce
            main: get_loss_func
        optimizer:
            module: torch.optim
            main: AdamW
            split_params: true
            lr_decay_factor: 0.8
            args:
                params: null
                lr: 0.001
                betas: [0.9, 0.999]
                eps: 0.00000001
                weight_decay: 0.0
                amsgrad: true
        lr_scheduler:
            schedule_mode: cos
            num_warmup_steps: 4000
            lr_end: 2e-7
        is_validation: true

train:
    callbacks:
        -
            name: checkpoint
            module: lightning.pytorch.callbacks
            main: ModelCheckpoint
            args:
                every_n_epochs: 1
                filename: "{epoch}"
                save_top_k: 1
                save_last: True
                monitor: epoch_val/loss
                mode: min
                verbose: False
                dirpath: null
        -
            name: tqdm
            module: lightning.pytorch.callbacks
            main: TQDMProgressBar
            args:
                refresh_rate: 1
                process_position: 0
    trainer:
        module: lightning.pytorch
        main: Trainer
        compile: False
        torch_flags: False
        channels_last: False
        args:
            accelerator: auto
            devices: auto
            strategy: ddp_find_unused_parameters_true
            num_nodes: 1
            precision: 32-true
            logger: null
            fast_dev_run: False
            max_epochs: 70
            log_every_n_steps: 100
            use_distributed_sampler: True
            sync_batchnorm: True
            check_val_every_n_epoch: 2
            val_check_interval: 1.0
            num_sanity_val_steps: 0
            enable_checkpointing: True
            enable_progress_bar: True
            enable_model_summary: True
            limit_train_batches: null
            limit_val_batches: null
            gradient_clip_val: 0.5
